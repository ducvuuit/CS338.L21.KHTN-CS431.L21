{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender_Estimation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3yl99hOe_F3"
      },
      "source": [
        "# **Age and Gender Estimation in TensorFlow ( Workbook 2, Gender Classification )**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMlbjEzffKQP"
      },
      "source": [
        "## 1) **Downloading the UTKFace dataset** \n",
        "Make sure to turn on GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PKqk30bZ1Z6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ad214c-bd12-4947-d77b-277a5874014f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj0md65mfR5_"
      },
      "source": [
        "\n",
        "Unzip the `utkface_23k.zip` file to the local directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzwQHuZsiAsr"
      },
      "source": [
        "# Replace with your path!\n",
        "#!unzip -q /content/drive/MyDrive/Datasets/utkface_23k.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKFRvNVZfXT9"
      },
      "source": [
        "\n",
        "Rename the directory from `utkace_23k` to `utkface23k`, in order to remove the underscore, which might cause errors while we're splitting the filename, to get the age of the person."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEptd_PoO6Qz"
      },
      "source": [
        "#!mv data/utkface_23k data/utkface23k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJORb4Jvsupm"
      },
      "source": [
        "working_dir = '/content/drive/MyDrive/Datasets/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb_CNn_ui6QT"
      },
      "source": [
        "# To download checkpoints, Keras models, TFLite models\n",
        "from google.colab import files\n",
        "# Life is incomplete without this statement!\n",
        "import tensorflow as tf\n",
        "# And this as well!\n",
        "import numpy as np\n",
        "# To visualize results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAgOhn0cfrkg"
      },
      "source": [
        "## 2) **Processing the data**\n",
        "\n",
        "*  Reading the image files as 3D NumPy arrays. Note, we'll use 3-channeled RGB images for training the model, so each array will have a shape of `[ img_width , img_height , 3 ]`.\n",
        "\n",
        "*  Split the filename so as to parse the gender of the person in corresponding image. We use the `tf.strings.split()` method for performing this task.\n",
        "\n",
        "*  We one-hot encode the gender, as we'll perform *a two-class* classification.\n",
        "\n",
        "Once this operations have been performed, we are left with $N$ samples where each sample consists of image array `[ 128 , 128 , 3 ]` and its corresponding label ( one-hot encoded ), the gender of that person, which has a shape `[ 1 , 2 ]`\n",
        "\n",
        "We'll use `tf.data.Dataset` as it helps us to process the data faster, taking advantage of parallel computing. The above two operations will be mapped on each filename using `tf.data.Dataset.map` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m67XqZMHirhz"
      },
      "source": [
        "# Image size for our model.\n",
        "MODEL_INPUT_IMAGE_SIZE = [ 128 , 128 ]\n",
        "\n",
        "# Fraction of the dataset to be used for testing.\n",
        "TRAIN_TEST_SPLIT = 0.3\n",
        "\n",
        "# Number of samples to take from dataset\n",
        "NUM_SAMPLES = 20000\n",
        "\n",
        "# Trick to one-hot encode the label.\n",
        "y1 = tf.constant( [ 1. , 0. ] , dtype='float32' ) \n",
        "y2 = tf.constant( [ 0. , 1. ] , dtype='float32' ) \n",
        "\n",
        "# This method will be mapped for each filename in `list_ds`. \n",
        "def parse_image( filename ):\n",
        "\n",
        "    # Read the image from the filename and resize it.\n",
        "    image_raw = tf.io.read_file( filename )\n",
        "    image = tf.image.decode_jpeg( image_raw , channels=3 ) \n",
        "    image = tf.image.resize( image , MODEL_INPUT_IMAGE_SIZE ) / 255\n",
        "\n",
        "    # Split the filename to get the age and the gender. Convert the age ( str ) and the gender ( str ) to dtype float32.\n",
        "    parts = tf.strings.split( tf.strings.split( filename , '/' )[ 2 ] , '_' )\n",
        "\n",
        "    # One-hot encode the label\n",
        "    gender = tf.strings.to_number( parts[ 1 ] )\n",
        "    gender_onehot = ( gender * y2 ) + ( ( 1 - gender ) * y1 )\n",
        "\n",
        "    return image , gender_onehot\n",
        "\n",
        "# List all the image files in the given directory.\n",
        "list_ds = tf.data.Dataset.list_files( working_dir + 'utkface23k/*' , shuffle=True )\n",
        "# Map `parse_image` method to all filenames.\n",
        "dataset = list_ds.map( parse_image , num_parallel_calls=tf.data.AUTOTUNE )\n",
        "dataset = dataset.take( NUM_SAMPLES )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNm64KUSfzwj"
      },
      "source": [
        "\n",
        "We create two splits from our dataset, one for training the model and another for testing the model. The fraction of the dataset which will be used for testing the model is determined by `TRAIN_TEST_SPLIT`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9aO3SH22mFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa3fc5df-9e44-4a46-e868-3a42fc311553"
      },
      "source": [
        "# Create train and test splits of the dataset.\n",
        "num_examples_in_test_ds = int(dataset.cardinality().numpy() * TRAIN_TEST_SPLIT)\n",
        "\n",
        "test_ds = dataset.take(num_examples_in_test_ds)\n",
        "train_ds = dataset.skip(num_examples_in_test_ds)\n",
        "\n",
        "print('Num examples in train ds {}'.format( train_ds.cardinality()))\n",
        "print('Num examples in test ds {}'.format( test_ds.cardinality()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num examples in train ds 14000\n",
            "Num examples in test ds 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtZnNB0Nm3g_"
      },
      "source": [
        "\n",
        "## 3) **The CNN Model**\n",
        "\n",
        "Our aim is to develop a model which has lesser parameters ( which implies lesser inference time and size ) but powerful enough so that it can generalize better.\n",
        "\n",
        "* The model takes in a batch of shape `[ None , 128 , 128 , 3 ]` and performs a number of convolutions on it as determined by `num_blocks`.\n",
        "* Each block consists of a sequence of layers : `Conv2D -> BatchNorm -> LeakyReLU`\n",
        "\n",
        "* If `lite_model` is set to `True`, we use  Separable Convolutionswhich have lesser parameters. We could achieve a *faster* model, compromising its performance.\n",
        "\n",
        "* We stack such`num_blocks` blocks sequentially, where the no. of filters for each layer is taken from `num_filters`.\n",
        "\n",
        "* Next we add a number of `Dense` layers to learn the features extracted by convolutional layers. Note, we also add a `Dropout` layer, to reduce overfitting. The `rate` for each `Dropout` layer is decreased subsequently for each layer, so that the learnability of `Dense` layer with lesser units.\n",
        "\n",
        "* The last `Dense` layer applies the softmax activation function which yields a probability distribution for the two classes `male` and `female`.\n",
        "\n",
        "* The output of the model is a tensor with shape `[ None, 2 ]`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qmw6DHVG2QD"
      },
      "source": [
        "# Negative slope coefficient for LeakyReLU.\n",
        "leaky_relu_alpha = 0.2\n",
        "\n",
        "lite_model = True\n",
        "\n",
        "# Define the conv block.\n",
        "def conv( x , num_filters , kernel_size=( 3 , 3 ) , strides=1 ):\n",
        "    if lite_model:\n",
        "        x = tf.keras.layers.SeparableConv2D( num_filters ,\n",
        "                                            kernel_size=kernel_size ,\n",
        "                                            strides=strides, \n",
        "                                            use_bias=False ,\n",
        "                                            kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                            kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                             )( x )\n",
        "    else:\n",
        "        x = tf.keras.layers.Conv2D( num_filters ,\n",
        "                                   kernel_size=kernel_size ,\n",
        "                                   strides=strides ,\n",
        "                                   use_bias=False ,\n",
        "                                   kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                   kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                    )( x )\n",
        "\n",
        "    x = tf.keras.layers.BatchNormalization()( x )\n",
        "    x = tf.keras.layers.LeakyReLU( leaky_relu_alpha )( x )\n",
        "    return x\n",
        "\n",
        "def dense( x , filters , dropout_rate ):\n",
        "    x = tf.keras.layers.Dense( filters , kernel_regularizer=tf.keras.regularizers.L2( 0.1 ) , bias_regularizer=tf.keras.regularizers.L2( 0.1 ) )( x )\n",
        "    x = tf.keras.layers.LeakyReLU( alpha=leaky_relu_alpha )( x )\n",
        "    x = tf.keras.layers.Dropout( dropout_rate )( x )\n",
        "    return x\n",
        "\n",
        "\n",
        "# No. of convolution layers to be added.\n",
        "num_blocks = 5\n",
        "# Num filters for each conv layer.\n",
        "num_filters = [ 16 , 32 , 64 , 128 , 256 , 256 ]\n",
        "# Kernel sizes for each conv layer.\n",
        "kernel_sizes = [ 3 , 3 , 3 , 3 , 3 , 3 ]\n",
        "\n",
        "# Init a Input Layer.\n",
        "inputs = tf.keras.layers.Input( shape=MODEL_INPUT_IMAGE_SIZE + [ 3 ] )\n",
        "\n",
        "# Add conv blocks sequentially\n",
        "x = inputs\n",
        "for i in range( num_blocks ):\n",
        "    x = conv( x , num_filters=num_filters[ i ] , kernel_size=kernel_sizes[ i ] )\n",
        "    x = tf.keras.layers.MaxPooling2D()( x )\n",
        "\n",
        "# Flatten the output of the last Conv layer.\n",
        "x = tf.keras.layers.Flatten()( x )\n",
        "conv_output = x \n",
        "\n",
        "# Add Dense layers ( Dense -> LeakyReLU -> Dropout )\n",
        "x = dense( conv_output , 256 , 0.6 )\n",
        "x = dense( x , 64 , 0.4 )\n",
        "x = dense( x , 32 , 0.2 )\n",
        "outputs = tf.keras.layers.Dense( 2 , activation='softmax' )( x )\n",
        "\n",
        "# Build the Model\n",
        "model = tf.keras.models.Model( inputs , outputs )\n",
        "\n",
        "# Uncomment the below to view the summary of the model.\n",
        "# model.summary()\n",
        "# tf.keras.utils.plot_model( model , to_file='architecture.png' )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JMUGVWqgAdR"
      },
      "source": [
        "## 4) **Compiling the model ( and other callbacks )**\n",
        "\n",
        "Once we've defined the architecture for our model, we'll compile our Keras model and also initialize some useful callbacks.\n",
        "\n",
        "* As we're performing classification, we'll use the Categorical Crossentropy loss function. See [`tf.keras.losses.CategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy).\n",
        "\n",
        "* We'll use the Adam optimizer for training our model. See [`tf.keras.optimizers.Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).\n",
        "\n",
        "* For evaluating the performance of our model, we measure the accuracy of our model. See [`tf.keras.metrics.Accuracy`](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy).\n",
        "\n",
        "\n",
        "#### Callbacks:\n",
        "\n",
        "* [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) to save the Keras model as an H5 file after every epoch.\n",
        "\n",
        "* [`tf.keras.callbacks.TensorBoard`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) to visualize the training with TensorBoard.\n",
        "\n",
        "* [`tf.keras.callbacks.EarlyStopping`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) to stop the training when the evaluation metric i.e the MAE stops improving on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cow71DK6kjUQ"
      },
      "source": [
        "learning_rate = 0.0001\n",
        "num_epochs = 10 \n",
        "batch_size = 128\n",
        "\n",
        "train_ds = train_ds.batch( batch_size ).repeat(num_epochs)\n",
        "test_ds = test_ds.batch( batch_size ).repeat(num_epochs)\n",
        "\n",
        "save_dir = 'train-1/cp.ckpt'\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint( save_dir )\n",
        "\n",
        "logdir = os.path.join( \"tb_logs\" , datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") )\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard( logdir )\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping( monitor='val_accuracy' , patience=3 )\n",
        "\n",
        "model.compile( \n",
        "    loss=tf.keras.losses.categorical_crossentropy , \n",
        "    optimizer = tf.keras.optimizers.Adam( learning_rate ) , \n",
        "    metrics =[ 'accuracy' ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtpRh9y0orKo"
      },
      "source": [
        "## 5) **Train and Evaluate the Model** 🏋🏻‍♂️\n",
        "\n",
        "Start the training loop with all callbacks packed in.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RddzZAhSgTQ5"
      },
      "source": [
        "model.fit( \n",
        "    train_ds, \n",
        "    epochs=num_epochs,  \n",
        "    validation_data=test_ds\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WVYKruLozh4"
      },
      "source": [
        "Evaluate the Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZKpG-IVBr_C"
      },
      "source": [
        "p = model.evaluate( test_ds )\n",
        "print( 'loss is {} \\n accuracy is {} %'.format( p[0] , p[1] * 100 ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spX1Piedo0-X"
      },
      "source": [
        "\n",
        "Save the Keras model to the local disk, so that we can resume training if needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5TtLuHZDFry"
      },
      "source": [
        "model_name = 'model_gender' #@param {type: \"string\"}\n",
        "model_name_ = model_name + '.h5'\n",
        "\n",
        "model.save( model_name_ )\n",
        "files.download( model_name_ ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSOFJqsf-uK9"
      },
      "source": [
        " \n",
        "## 6) **Convert to TensorFlow Lite format**\n",
        "\n",
        "Our model is to be deployed in an Android app, where we'll use [TF Lite Android](https://bintray.com/google/tensorflow/tensorflow-lite) package to parse the model and make predictions.\n",
        "\n",
        "We use the `TFLiteConverter` API to convert our Keras Model ( `.h5` ) to a TF Lite buffer ( `.tflite` ). We'll produce two TF Lite buffers, one with float16 quantization and other non-quantized model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwmMTQxyhToJ"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model( model )\n",
        "converter.optimizations = [ tf.lite.Optimize.DEFAULT ]\n",
        "converter.target_spec.supported_types = [ tf.float16 ]\n",
        "buffer = converter.convert()\n",
        "\n",
        "open( '{}_q.tflite'.format( model_name ) , 'wb' ).write( buffer )\n",
        "files.download( '{}_q.tflite'.format( model_name ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5VTeSnGAhm_"
      },
      "source": [
        "\n",
        "For conversion to a non-quantized TF Lite buffer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jnurapqK6fw"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model( model )\n",
        "buffer = converter.convert()\n",
        "\n",
        "open( '{}_nonq.tflite'.format( model_name ) , 'wb' ).write( buffer )\n",
        "files.download( '{}_nonq.tflite'.format( model_name ) )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}