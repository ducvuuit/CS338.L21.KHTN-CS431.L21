{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Age_Estimation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2bkkoSFDBre"
      },
      "source": [
        "\n",
        "# **Age Estimation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1t1Vq_ZEiuq"
      },
      "source": [
        "\n",
        "## 1) **Load UTKFace dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__PT9Yn_djmV"
      },
      "source": [
        "!gdown --id 1Y8EOFLIRCcKpe_e0pO03yCAosTRjRMtC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzwQHuZsiAsr"
      },
      "source": [
        "!unzip -q /content/UTKFace.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb_CNn_ui6QT"
      },
      "source": [
        "# To download checkpoints, Keras models, TFLite models\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLOWdGmrEg1T"
      },
      "source": [
        "\n",
        "## 2) **Processing the data**\n",
        "\n",
        "* Đọc tệp hình ảnh dưới dạng mảng 3 chiều NumPy. Lưu ý, chúng tôi sẽ sử dụng hình ảnh RGB, vì vậy mỗi mảng sẽ có hình dạng `[ img_width , img_height , 3 ]`.\n",
        "\n",
        "* Tách tên tệp để phân tích độ tuổi của người trong hình ảnh tương ứng. Chúng tôi sử dụng `tf.strings.split()`.\n",
        "\n",
        "* Độ tuổi cao nhất trong dataset là 116, nên dùng tuổi/116 để chuẩn hóa\n",
        "\n",
        "\n",
        "Khi các thao tác này đã được thực hiện, chúng ta nhận được các mẫu trong đó mỗi mẫu bao gồm mảng hình ảnh `[ 200 , 200 , 3 ]` và label tương ứng, tuổi của người đó`[ 1 , ]`\n",
        "\n",
        "Dùng `tf.data.Dataset` để xử lý nhanh hơn(tính toán song song).  `tf.data.Dataset.map` để map 2 cái ở trên lại.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmrBjev8eO4Z"
      },
      "source": [
        "n = len(os.listdir('/content/data/UTKFace'))\n",
        "n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m67XqZMHirhz"
      },
      "source": [
        "MODEL_INPUT_IMAGE_SIZE = [ 200 , 200 ]\n",
        "TRAIN_TEST_SPLIT = 0.3\n",
        "\n",
        "# This method will be mapped for each filename in `list_ds`. \n",
        "def parse_image( filename ):\n",
        "\n",
        "    # Read the image from the filename and resize it.\n",
        "    image_raw = tf.io.read_file( filename )\n",
        "    image = tf.image.decode_jpeg( image_raw , channels=3 ) \n",
        "    image = tf.image.resize( image , MODEL_INPUT_IMAGE_SIZE ) / 255\n",
        "\n",
        "    # Split the filename to get the age and the gender. Convert the age ( str ) and the gender ( str ) to dtype float32.\n",
        "    parts = tf.strings.split( tf.strings.split( filename , '/' )[ 2 ] , '_' )\n",
        "\n",
        "    # Normalize\n",
        "    age = tf.strings.to_number( parts[ 0 ] ) / 116\n",
        "\n",
        "    return image , age\n",
        "\n",
        "# List all the image files in the given directory.\n",
        "list_ds = tf.data.Dataset.list_files( 'data/UTKFace/*' , shuffle=True )\n",
        "\n",
        "# Map `parse_image` method to all filenames.\n",
        "dataset = list_ds.map( parse_image , num_parallel_calls=tf.data.AUTOTUNE )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYSpbniQHLnm"
      },
      "source": [
        "\n",
        "Tạo tập train và test bằng `TRAIN_TEST_SPLIT`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9aO3SH22mFK"
      },
      "source": [
        "\n",
        "# Create train and test splits of the dataset.\n",
        "num_examples_in_test_ds = int( dataset.cardinality().numpy() * TRAIN_TEST_SPLIT )\n",
        "\n",
        "test_ds = dataset.take( num_examples_in_test_ds )\n",
        "train_ds = dataset.skip( num_examples_in_test_ds )\n",
        "\n",
        "print( 'Num examples in train ds {}'.format( train_ds.cardinality() ) )\n",
        "print( 'Num examples in test ds {}'.format( test_ds.cardinality() ) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdCOHkLQphjz"
      },
      "source": [
        "Vì hướng tới việc triển khai ứng dụng trên mobile, nên chúng tôi chọn mô hình đơn giản nhưng vẫn đủ mạnh để khái quát tốt. Vì vậy nên dùng bài toán hồi quy để dự đoán tuổi.\n",
        "\n",
        "- Model nhận vào [ None , 200 , 200 , 3 ] và đi qua num_blocks\n",
        "- Mỗi block gồm : Conv2D -> BatchNorm -> LeakyReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qmw6DHVG2QD"
      },
      "source": [
        "\n",
        "# Negative slope coefficient for LeakyReLU.\n",
        "leaky_relu_alpha = 0.2\n",
        "\n",
        "lite_model = False\n",
        "\n",
        "# Define the conv block.\n",
        "def conv( x , num_filters , kernel_size=( 3 , 3 ) , strides=1 ):\n",
        "    if lite_model:\n",
        "        x = tf.keras.layers.SeparableConv2D( num_filters ,\n",
        "                                            kernel_size=kernel_size ,\n",
        "                                            strides=strides, \n",
        "                                            use_bias=False ,\n",
        "                                            kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                            kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                             )( x )\n",
        "    else:\n",
        "        x = tf.keras.layers.Conv2D( num_filters ,\n",
        "                                   kernel_size=kernel_size ,\n",
        "                                   strides=strides ,\n",
        "                                   use_bias=False ,\n",
        "                                   kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                   kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                    )( x )\n",
        "\n",
        "    x = tf.keras.layers.BatchNormalization()( x )\n",
        "    x = tf.keras.layers.LeakyReLU( leaky_relu_alpha )( x )\n",
        "    return x\n",
        "\n",
        "def dense( x , filters , dropout_rate ):\n",
        "    x = tf.keras.layers.Dense( filters , kernel_regularizer=tf.keras.regularizers.L2( 0.1 ) , bias_regularizer=tf.keras.regularizers.L2( 0.1 ) )( x )\n",
        "    x = tf.keras.layers.LeakyReLU( alpha=leaky_relu_alpha )( x )\n",
        "    x = tf.keras.layers.Dropout( dropout_rate )( x )\n",
        "    return x\n",
        "\n",
        "\n",
        "# No. of convolution layers to be added.\n",
        "num_blocks = 6\n",
        "# Num filters for each conv layer.\n",
        "num_filters = [ 16 , 32 , 64 , 128 , 256 , 256 ]\n",
        "# Kernel sizes for each conv layer.\n",
        "kernel_sizes = [ 3 , 3 , 3 , 3 , 3 , 3 ]\n",
        "\n",
        "# Init a Input Layer.\n",
        "inputs = tf.keras.layers.Input( shape=MODEL_INPUT_IMAGE_SIZE + [ 3 ] )\n",
        "\n",
        "# Add conv blocks sequentially\n",
        "x = inputs\n",
        "for i in range( num_blocks ):\n",
        "    x = conv( x , num_filters=num_filters[ i ] , kernel_size=kernel_sizes[ i ] )\n",
        "    x = tf.keras.layers.MaxPooling2D()( x )\n",
        "\n",
        "# Flatten the output of the last Conv layer.\n",
        "x = tf.keras.layers.Flatten()( x )\n",
        "conv_output = x \n",
        "\n",
        "# Add Dense layers ( Dense -> LeakyReLU -> Dropout )\n",
        "x = dense( conv_output , 256 , 0.6 )\n",
        "x = dense( x , 64 , 0.4 )\n",
        "x = dense( x , 32 , 0.2 )\n",
        "outputs = tf.keras.layers.Dense( 1 , activation='relu' )( x )\n",
        "\n",
        "# Build the Model\n",
        "model = tf.keras.models.Model( inputs , outputs )\n",
        "\n",
        "# Uncomment the below to view the summary of the model.\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrHarErGuFKa"
      },
      "source": [
        "\n",
        "## 4) **Compiling the model**\n",
        "\n",
        "Khi đã định nghĩa xong kiến trúc mô hình, chúng ta sẽ compile model bằng một số hàm sau:\n",
        "\n",
        "* Dùng Mean Absolute Error(MAE) để làm loss function. `tf.keras.losses.mean_absolute_error`\n",
        "\n",
        "* Dùng Adam optimizer để tối ưu model `tf.keras.optimizers.Adam`\n",
        "\n",
        "* Vẫn dùng Mean Absolute Error để đánh giá. `tf.keras.metrics.MeanAbsoluteError`\n",
        "\n",
        "* `tf.keras.callbacks.ModelCheckpoint` save Kereras model sau mỗi epoch.\n",
        "\n",
        "* `tf.keras.callbacks.TensorBoard` để trực quan hóa training trên TensorBoard \n",
        "\n",
        "* `tf.keras.callbacks.LearningRateScheduler` để giam learning rate sau số epoch nhất định.\n",
        "```\n",
        "def scheduler( epochs , learning_rate ):\n",
        "    if epochs < num_epochs * 0.25:\n",
        "        return learning_rate\n",
        "    elif epochs < num_epochs * 0.5:\n",
        "        return 0.0005\n",
        "    elif epochs < num_epochs * 0.75:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        return 0.000095\n",
        "```\n",
        "\n",
        "* `tf.keras.callbacks.EarlyStopping` dùng để dừng train khi kết quả evaluate không được cải thiện nữa.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbvs6byaspdK"
      },
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "num_epochs =  50\n",
        "batch_size = 128\n",
        "# Batch and repeat `train_ds` and `test_ds`.\n",
        "train_ds = train_ds.batch( batch_size )\n",
        "test_ds = test_ds.batch( batch_size )\n",
        "\n",
        "# Init ModelCheckpoint callback\n",
        "save_dir_ = 'model_1'  \n",
        "save_dir = save_dir_ + '/{epoch:02d}-{val_mae:.2f}.h5'\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint( \n",
        "    save_dir , \n",
        "    save_best_only=True , \n",
        "    monitor='val_mae' , \n",
        "    mode='min' , \n",
        ")\n",
        "\n",
        "tb_log_name = 'model_1'\n",
        "# Init TensorBoard Callback\n",
        "logdir = os.path.join( \"tb_logs\" , tb_log_name )\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard( logdir )\n",
        "\n",
        "# Init LR Scheduler\n",
        "def scheduler( epochs , learning_rate ):\n",
        "    if epochs < num_epochs * 0.25:\n",
        "        return learning_rate\n",
        "    elif epochs < num_epochs * 0.5:\n",
        "        return 0.0005\n",
        "    elif epochs < num_epochs * 0.75:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        return 0.000095\n",
        "\n",
        "lr_schedule_callback = tf.keras.callbacks.LearningRateScheduler( scheduler )\n",
        "\n",
        "# Init Early Stopping callback\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping( monitor='val_mae' , patience=10 )\n",
        "\n",
        "# Compile the model\n",
        "model.compile( \n",
        "    loss=tf.keras.losses.mean_absolute_error ,\n",
        "    optimizer = tf.keras.optimizers.Adam( learning_rate ) , \n",
        "    metrics=[ 'mae' ]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCVYNawQjXRj"
      },
      "source": [
        "visualize the training of the model in TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycIUYrp65w7r"
      },
      "source": [
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tb_logs/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M-KwmgEj0y1"
      },
      "source": [
        "\n",
        "\n",
        "## 5) **Train and Evaluate the Model** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cow71DK6kjUQ"
      },
      "source": [
        "\n",
        "model.fit( \n",
        "    train_ds, \n",
        "    epochs=num_epochs,  \n",
        "    validation_data=test_ds, \n",
        "    callbacks=[ checkpoint_callback , tensorboard_callback , lr_schedule_callback , early_stopping_callback ]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZKpG-IVBr_C"
      },
      "source": [
        "# Evaluate Model\n",
        "p = model.evaluate( test_ds )\n",
        "print( p )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIm_gNWnMSUk"
      },
      "source": [
        "batch_size = 128\n",
        "model = tf.keras.models.load_model( '/content/model_1/48-0.02.h5' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5TtLuHZDFry"
      },
      "source": [
        "# Save model\n",
        "model_name = 'model_age' \n",
        "model_name_ = model_name + '.h5'\n",
        "\n",
        "model.save( model_name_ )\n",
        "files.download( model_name_ ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_JYNaYcnuCp"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x28Xr22f2Hny"
      },
      "source": [
        "\n",
        "## 6) **Visualize the results**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kiV_xRc2QzD"
      },
      "source": [
        "\n",
        "fig = plt.figure( figsize=( 10 , 15 ) )\n",
        "rows = 5\n",
        "columns = 2\n",
        "\n",
        "i = 1\n",
        "for image , label in test_ds.unbatch().take( 10 ):\n",
        "    image = image.numpy()\n",
        "    fig.add_subplot( rows , columns , i )\n",
        "    plt.imshow( image )\n",
        "    label_ = int( model.predict( np.expand_dims( image , 0 ) ) * 116 )\n",
        "    plt.axis( 'off' )\n",
        "    plt.title( 'Predicted age : {} , actual age : {}'.format( label_ , int( label.numpy() * 116 ) ) )\n",
        "    i += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TguIhef3cSAo"
      },
      "source": [
        "# test real image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSOFJqsf-uK9"
      },
      "source": [
        "## 7) **Convert to TensorFlow Lite format**\n",
        "\n",
        "Để model chạy được trên mobile, chúng ta sẽ dùng TF Lite Android\n",
        "\n",
        "Dùng `TFLiteConverter` API để chuyển Keras Model ( `.h5` ) thành ( `.tflite`).chuyển thành 2 TF Lite, quantization và non-quantized model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwmMTQxyhToJ"
      },
      "source": [
        "#quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model( model )\n",
        "converter.optimizations = [ tf.lite.Optimize.DEFAULT ]\n",
        "converter.target_spec.supported_types = [ tf.float16 ]\n",
        "buffer = converter.convert()\n",
        "# open( '{}_q.tflite'.format( model_name ) , 'wb' ).write( buffer )\n",
        "# files.download( '{}_q.tflite'.format( model_name ) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jnurapqK6fw"
      },
      "source": [
        "#non-quantized\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model( model )\n",
        "buffer = converter.convert()\n",
        "\n",
        "open( '{}_nonq.tflite'.format( model_name ) , 'wb' ).write( buffer )\n",
        "files.download( '{}_nonq.tflite'.format( model_name ) )\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}