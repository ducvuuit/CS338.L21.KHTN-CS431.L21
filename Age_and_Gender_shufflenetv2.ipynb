{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Age_and_Gender_shufflenetv2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMQMS5ek8aB5",
        "outputId": "9d11e9de-bc7d-4976-b74e-f3fb0a883cc8"
      },
      "source": [
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1MB 1.4MB/s eta 0:13:13tcmalloc: large alloc 1147494400 bytes == 0x55f180b00000 @  0x7f1fc796f615 0x55f146bec02c 0x55f146ccc17a 0x55f146beee4d 0x55f146ce0c0d 0x55f146c630d8 0x55f146c5dc35 0x55f146bf073a 0x55f146c62f40 0x55f146c5dc35 0x55f146bf073a 0x55f146c5f93b 0x55f146ce1a56 0x55f146c5efb3 0x55f146ce1a56 0x55f146c5efb3 0x55f146ce1a56 0x55f146c5efb3 0x55f146ce1a56 0x55f146d630d1 0x55f146cc42f9 0x55f146c2eac4 0x55f146bef8a9 0x55f146c63b0a 0x55f146bf065a 0x55f146c5eb0e 0x55f146c5e235 0x55f146bf073a 0x55f146c5eb0e 0x55f146bf065a 0x55f146c5eb0e\n",
            "\u001b[K     |█████████████████               | 1055.7MB 1.3MB/s eta 0:12:03tcmalloc: large alloc 1434370048 bytes == 0x55f1c5156000 @  0x7f1fc796f615 0x55f146bec02c 0x55f146ccc17a 0x55f146beee4d 0x55f146ce0c0d 0x55f146c630d8 0x55f146c5dc35 0x55f146bf073a 0x55f146c62f40 0x55f146c5dc35 0x55f146bf073a 0x55f146c5f93b 0x55f146ce1a56 0x55f146c5efb3 0x55f146ce1a56 0x55f146c5efb3 0x55f146ce1a56 0x55f146c5efb3 0x55f146ce1a56 0x55f146d630d1 0x55f146cc42f9 0x55f146c2eac4 0x55f146bef8a9 0x55f146c63b0a 0x55f146bf065a 0x55f146c5eb0e 0x55f146c5e235 0x55f146bf073a 0x55f146c5eb0e 0x55f146bf065a 0x55f146c5eb0e\n",
            "\u001b[K     |█████████████████████▋          | 1336.2MB 1.4MB/s eta 0:07:45tcmalloc: large alloc 1792966656 bytes == 0x55f149f88000 @  0x7f1fc796f615 0x55f146bec02c 0x55f146ccc17a 0x55f146beee4d 0x55f146ce0c0d 0x55f146c630d8 0x55f146c5dc35 0x55f146bf073a 0x55f146c62f40 0x55f146c5dc35 0x55f146bf073a 0x55f146c5f93b 0x55f146ce1a56 0x55f146c5efb3 0x55f146ce1a56 0x55f146c5efb3 0x55f146ce1a56 0x55f146c5efb3 0x55f146ce1a56 0x55f146d630d1 0x55f146cc42f9 0x55f146c2eac4 0x55f146bef8a9 0x55f146c63b0a 0x55f146bf065a 0x55f146c5eb0e 0x55f146c5e235 0x55f146bf073a 0x55f146c5eb0e 0x55f146bf065a 0x55f146c5eb0e\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1MB 1.2MB/s eta 0:03:57tcmalloc: large alloc 2241208320 bytes == 0x55f1b4d70000 @  0x7f1fc796f615 0x55f146bec02c 0x55f146ccc17a 0x55f146beee4d 0x55f146ce0c0d 0x55f146c630d8 0x55f146c5dc35 0x55f146bf073a 0x55f146c62f40 0x55f146c5dc35 0x55f146bf073a 0x55f146c5f93b 0x55f146ce1a56 0x55f146c5efb3 0x55f146ce1a56 0x55f146c5efb3 0x55f146ce1a56 0x55f146c5efb3 0x55f146ce1a56 0x55f146d630d1 0x55f146cc42f9 0x55f146c2eac4 0x55f146bef8a9 0x55f146c63b0a 0x55f146bf065a 0x55f146c5eb0e 0x55f146c5e235 0x55f146bf073a 0x55f146c5eb0e 0x55f146bf065a 0x55f146c5eb0e\n",
            "\u001b[K     |████████████████████████████████| 1982.2MB 1.2MB/s eta 0:00:01tcmalloc: large alloc 1982251008 bytes == 0x55f23a6d2000 @  0x7f1fc796e1e7 0x55f146c21ae7 0x55f146bec02c 0x55f146ccc17a 0x55f146beee4d 0x55f146ce0c0d 0x55f146c630d8 0x55f146c5dc35 0x55f146bf073a 0x55f146c5ed67 0x55f146c5dc35 0x55f146bf073a 0x55f146c5ed67 0x55f146c5dc35 0x55f146bf073a 0x55f146c5ed67 0x55f146c5dc35 0x55f146bf073a 0x55f146c5ed67 0x55f146c5dc35 0x55f146bf073a 0x55f146c5ed67 0x55f146bf065a 0x55f146c5ed67 0x55f146c5dc35 0x55f146bf073a 0x55f146c5f93b 0x55f146c5dc35 0x55f146bf073a 0x55f146c5f93b 0x55f146c5dc35\n",
            "tcmalloc: large alloc 2477817856 bytes == 0x55f324dc2000 @  0x7f1fc796f615 0x55f146bec02c 0x55f146ccc17a 0x55f146beee4d 0x55f146ce0c0d 0x55f146c630d8 0x55f146c5dc35 0x55f146bf073a 0x55f146c5ed67 0x55f146c5dc35 0x55f146bf073a 0x55f146c5ed67 0x55f146c5dc35 0x55f146bf073a 0x55f146c5ed67 0x55f146c5dc35 0x55f146bf073a 0x55f146c5ed67 0x55f146c5dc35 0x55f146bf073a 0x55f146c5ed67 0x55f146bf065a 0x55f146c5ed67 0x55f146c5dc35 0x55f146bf073a 0x55f146c5f93b 0x55f146c5dc35 0x55f146bf073a 0x55f146c5f93b 0x55f146c5dc35 0x55f146bf0dd1\n",
            "\u001b[K     |████████████████████████████████| 1982.2MB 3.8kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6MB 203kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n",
            "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.8.0+cu111 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "Successfully installed torch-1.8.0+cu111 torchvision-0.9.0+cu111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cizjk9AQ4F1r"
      },
      "source": [
        "# !pip install torch==1.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T69X3oo5SGiH",
        "outputId": "4c6b5b3c-06fb-4c09-e89b-d73039552e2f"
      },
      "source": [
        "!gdown --id 1Y8EOFLIRCcKpe_e0pO03yCAosTRjRMtC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y8EOFLIRCcKpe_e0pO03yCAosTRjRMtC\n",
            "To: /content/UTKFace.zip\n",
            "347MB [00:03, 109MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCB4dhcAS0FY"
      },
      "source": [
        "!unzip -q /content/UTKFace.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWaagvdOS6A1"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri_iti5uTA5f",
        "outputId": "46723037-2107-43c8-b8ee-e23825ada274"
      },
      "source": [
        "n = len(os.listdir('/content/data/UTKFace'))\n",
        "n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23708"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqiQ9pVz5Hmd",
        "outputId": "332b59cb-8fcb-4652-d799-a29715e75a77"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  sample_data  UTKFace.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YozGLLB0Svr"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQbF-aVYqfRc"
      },
      "source": [
        "# Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEdPHLSsqhnZ"
      },
      "source": [
        "class AgeDataset(Dataset):\n",
        "  def __init__(self, img_files, img_dir):\n",
        "    self.img_dir = img_dir\n",
        "    self.img_files = img_files\n",
        "    self.image_transforms = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_files)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_name = self.img_files[index]\n",
        "    gender = int(img_name.split(\"_\")[1])\n",
        "    image = Image.open(os.path.join(self.img_dir, img_name))\n",
        "\n",
        "    image = self.image_transforms(image)\n",
        "    gender = torch.tensor(gender, dtype=torch.long)\n",
        "\n",
        "    return image, gender"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7CoAx9EnRtf",
        "outputId": "c177b3e3-c517-4f6e-e6be-0ff2440d33eb"
      },
      "source": [
        "img_dir = \"data/UTKFace/\"\n",
        "train_val_ratio = 0.3\n",
        "\n",
        "img_filenames = os.listdir(img_dir)\n",
        "random.shuffle(img_filenames)\n",
        "split = int(train_val_ratio * len(img_filenames))\n",
        "\n",
        "train_files = img_filenames[split:]\n",
        "val_files = img_filenames[:split]\n",
        "print(len(train_files), len(val_files))\n",
        "\n",
        "train_set = AgeDataset(train_files, img_dir)\n",
        "val_set = AgeDataset(val_files, img_dir)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "val_dataloader = DataLoader(val_set, batch_size=128, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16596 7112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-34RJ5Qrpq6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c71276-d245-444b-bd3a-6011c8e91aaa"
      },
      "source": [
        "for img, label in train_dataloader:\n",
        "  print(img, label)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[-1.5528, -1.6555, -1.7412,  ..., -1.9980, -1.9809, -1.9638],\n",
            "          [-1.5528, -1.6727, -1.7583,  ..., -1.9809, -1.9638, -1.9638],\n",
            "          [-1.5528, -1.6727, -1.7583,  ..., -1.9638, -1.9467, -1.9467],\n",
            "          ...,\n",
            "          [-1.7412, -1.7412, -1.7583,  ..., -0.5596, -0.7137, -0.8164],\n",
            "          [-1.8782, -1.8782, -1.8953,  ..., -0.5424, -0.7137, -0.8164],\n",
            "          [-1.9638, -1.9638, -1.9809,  ..., -0.5424, -0.7137, -0.8164]],\n",
            "\n",
            "         [[-1.3529, -1.4580, -1.5455,  ..., -1.7381, -1.7206, -1.7031],\n",
            "          [-1.3529, -1.4755, -1.5630,  ..., -1.7206, -1.7031, -1.7031],\n",
            "          [-1.3529, -1.4755, -1.5630,  ..., -1.7031, -1.6856, -1.6856],\n",
            "          ...,\n",
            "          [-1.6155, -1.6155, -1.6331,  ..., -1.0553, -1.1954, -1.2654],\n",
            "          [-1.7556, -1.7556, -1.7731,  ..., -1.0553, -1.1954, -1.2654],\n",
            "          [-1.8431, -1.8431, -1.8606,  ..., -1.0553, -1.1954, -1.2654]],\n",
            "\n",
            "         [[-1.2990, -1.4036, -1.4907,  ..., -1.4907, -1.4733, -1.4559],\n",
            "          [-1.2990, -1.4210, -1.5081,  ..., -1.4733, -1.4559, -1.4559],\n",
            "          [-1.2990, -1.4210, -1.5081,  ..., -1.4559, -1.4384, -1.4384],\n",
            "          ...,\n",
            "          [-1.4733, -1.4733, -1.4907,  ..., -1.0724, -1.1770, -1.2293],\n",
            "          [-1.6127, -1.6127, -1.6302,  ..., -1.0550, -1.1770, -1.2293],\n",
            "          [-1.6999, -1.6999, -1.7173,  ..., -1.0550, -1.1770, -1.2293]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9817,  1.0331,  1.0844,  ...,  1.8722,  1.7352,  1.6495],\n",
            "          [ 0.9303,  0.9817,  1.0331,  ...,  1.8893,  1.7694,  1.6838],\n",
            "          [ 0.8961,  0.9474,  0.9988,  ...,  1.9235,  1.7865,  1.7180],\n",
            "          ...,\n",
            "          [ 0.3138,  0.2624,  0.1939,  ...,  2.1975,  2.2147,  2.2147],\n",
            "          [ 0.2282,  0.1768,  0.1083,  ...,  2.1462,  2.1462,  2.1462],\n",
            "          [ 0.1597,  0.1083,  0.0398,  ...,  2.0777,  2.0777,  2.0777]],\n",
            "\n",
            "         [[ 0.9755,  1.0280,  1.0805,  ...,  1.8859,  1.7458,  1.6583],\n",
            "          [ 0.9230,  0.9755,  1.0280,  ...,  1.9034,  1.7808,  1.6933],\n",
            "          [ 0.8880,  0.9405,  0.9930,  ...,  1.9384,  1.7983,  1.7283],\n",
            "          ...,\n",
            "          [-0.2850, -0.3375, -0.4076,  ...,  1.9034,  1.9384,  1.9734],\n",
            "          [-0.3725, -0.4251, -0.4951,  ...,  1.8859,  1.9209,  1.9559],\n",
            "          [-0.4426, -0.4951, -0.5476,  ...,  1.8508,  1.8683,  1.9034]],\n",
            "\n",
            "         [[ 1.7337,  1.7860,  1.8383,  ...,  2.3960,  2.2566,  2.2043],\n",
            "          [ 1.6814,  1.7337,  1.7860,  ...,  2.4134,  2.2914,  2.2391],\n",
            "          [ 1.6465,  1.6988,  1.7511,  ...,  2.4483,  2.3263,  2.2740],\n",
            "          ...,\n",
            "          [-0.0441, -0.0964, -0.2010,  ...,  1.9428,  1.9603,  1.9951],\n",
            "          [-0.1312, -0.1835, -0.2881,  ...,  1.9254,  1.9428,  1.9777],\n",
            "          [-0.2010, -0.2532, -0.3404,  ...,  1.8731,  1.8905,  1.9254]]],\n",
            "\n",
            "\n",
            "        [[[-1.6384, -1.6384, -1.6384,  ..., -1.6727, -1.6727, -1.6727],\n",
            "          [-1.6384, -1.6384, -1.6384,  ..., -1.6727, -1.6727, -1.6727],\n",
            "          [-1.6384, -1.6384, -1.6384,  ..., -1.6727, -1.6727, -1.6727],\n",
            "          ...,\n",
            "          [-1.4843, -1.4843, -1.4843,  ..., -0.9020, -0.9020, -0.9020],\n",
            "          [-1.4672, -1.4672, -1.4672,  ..., -0.9192, -0.9020, -0.9020],\n",
            "          [-1.4672, -1.4672, -1.4672,  ..., -0.8849, -0.8678, -0.8678]],\n",
            "\n",
            "         [[-1.8081, -1.8081, -1.8081,  ..., -1.7906, -1.7906, -1.7556],\n",
            "          [-1.8081, -1.8081, -1.8081,  ..., -1.7906, -1.7906, -1.7556],\n",
            "          [-1.8081, -1.8081, -1.8081,  ..., -1.7906, -1.7906, -1.7556],\n",
            "          ...,\n",
            "          [-1.6331, -1.6331, -1.6331,  ..., -1.3179, -1.3179, -1.3179],\n",
            "          [-1.6155, -1.6155, -1.6155,  ..., -1.3354, -1.3179, -1.3179],\n",
            "          [-1.6155, -1.6155, -1.6155,  ..., -1.3529, -1.3354, -1.3354]],\n",
            "\n",
            "         [[-1.4907, -1.4907, -1.4907,  ..., -1.5604, -1.5604, -1.5430],\n",
            "          [-1.4907, -1.4907, -1.4907,  ..., -1.5604, -1.5604, -1.5430],\n",
            "          [-1.4907, -1.4907, -1.4907,  ..., -1.5604, -1.5604, -1.5430],\n",
            "          ...,\n",
            "          [-1.4559, -1.4559, -1.4559,  ..., -1.2641, -1.2641, -1.2641],\n",
            "          [-1.4384, -1.4384, -1.4384,  ..., -1.2816, -1.2641, -1.2641],\n",
            "          [-1.4384, -1.4384, -1.4384,  ..., -1.2816, -1.2641, -1.2641]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.7583, -1.7583, -1.7583,  ..., -1.4843, -1.4843, -1.4843],\n",
            "          [-1.7583, -1.7583, -1.7583,  ..., -1.4843, -1.4843, -1.4843],\n",
            "          [-1.7754, -1.7754, -1.7754,  ..., -1.4843, -1.4843, -1.4843],\n",
            "          ...,\n",
            "          [-1.9124, -1.9124, -1.9124,  ..., -1.8097, -1.7925, -1.7925],\n",
            "          [-1.9124, -1.9124, -1.9124,  ..., -1.7925, -1.7754, -1.7754],\n",
            "          [-1.9124, -1.9124, -1.9124,  ..., -1.7925, -1.7754, -1.7583]],\n",
            "\n",
            "         [[-1.7731, -1.7731, -1.7731,  ..., -1.5630, -1.5630, -1.5630],\n",
            "          [-1.7731, -1.7731, -1.7731,  ..., -1.5630, -1.5630, -1.5630],\n",
            "          [-1.7906, -1.7906, -1.7906,  ..., -1.5630, -1.5630, -1.5630],\n",
            "          ...,\n",
            "          [-1.8431, -1.8431, -1.8431,  ..., -1.7381, -1.7206, -1.7206],\n",
            "          [-1.8431, -1.8431, -1.8431,  ..., -1.7206, -1.7031, -1.7031],\n",
            "          [-1.8431, -1.8431, -1.8431,  ..., -1.7206, -1.7031, -1.6856]],\n",
            "\n",
            "         [[-1.5430, -1.5430, -1.5430,  ..., -1.4907, -1.4907, -1.4907],\n",
            "          [-1.5430, -1.5430, -1.5430,  ..., -1.4907, -1.4907, -1.4907],\n",
            "          [-1.5604, -1.5604, -1.5604,  ..., -1.4907, -1.4907, -1.4907],\n",
            "          ...,\n",
            "          [-1.6476, -1.6476, -1.6476,  ..., -1.5779, -1.5604, -1.5604],\n",
            "          [-1.6476, -1.6476, -1.6476,  ..., -1.5604, -1.5430, -1.5430],\n",
            "          [-1.6476, -1.6476, -1.6476,  ..., -1.5604, -1.5430, -1.5256]]],\n",
            "\n",
            "\n",
            "        [[[-0.9705, -0.9534, -0.9534,  ..., -0.9705, -0.8335, -0.7650],\n",
            "          [-0.9705, -0.9534, -0.9534,  ..., -1.0048, -0.8849, -0.8164],\n",
            "          [-0.9705, -0.9534, -0.9534,  ..., -1.0219, -0.9534, -0.9020],\n",
            "          ...,\n",
            "          [-1.5357, -1.5357, -1.5185,  ..., -0.3541, -0.3712, -0.3712],\n",
            "          [-1.5528, -1.5528, -1.5357,  ..., -0.3712, -0.3541, -0.3541],\n",
            "          [-1.5699, -1.5528, -1.5357,  ..., -0.3883, -0.3541, -0.3369]],\n",
            "\n",
            "         [[-1.0203, -1.0028, -1.0028,  ..., -1.0553, -0.9153, -0.8452],\n",
            "          [-1.0203, -1.0028, -1.0028,  ..., -1.0903, -0.9678, -0.8978],\n",
            "          [-1.0203, -1.0028, -1.0028,  ..., -1.1078, -1.0203, -0.9678],\n",
            "          ...,\n",
            "          [-1.4930, -1.4930, -1.4755,  ..., -0.4251, -0.4426, -0.4426],\n",
            "          [-1.5105, -1.5105, -1.4930,  ..., -0.4426, -0.4251, -0.4251],\n",
            "          [-1.5280, -1.5105, -1.4930,  ..., -0.4601, -0.4251, -0.4076]],\n",
            "\n",
            "         [[-1.4733, -1.4559, -1.4733,  ..., -1.3513, -1.2467, -1.1770],\n",
            "          [-1.4733, -1.4559, -1.4733,  ..., -1.3861, -1.2990, -1.2293],\n",
            "          [-1.4733, -1.4559, -1.4559,  ..., -1.4384, -1.3687, -1.3339],\n",
            "          ...,\n",
            "          [-1.5256, -1.5256, -1.5081,  ..., -1.1421, -1.1596, -1.1596],\n",
            "          [-1.5430, -1.5430, -1.5256,  ..., -1.1596, -1.1421, -1.1421],\n",
            "          [-1.5604, -1.5430, -1.5256,  ..., -1.1770, -1.1421, -1.1247]]],\n",
            "\n",
            "\n",
            "        [[[-1.4843, -1.4329, -1.3815,  ...,  1.9749,  1.9749,  1.9749],\n",
            "          [-1.4329, -1.3815, -1.3130,  ...,  1.9749,  1.9749,  1.9749],\n",
            "          [-1.3644, -1.3130, -1.2274,  ...,  1.9749,  1.9749,  1.9749],\n",
            "          ...,\n",
            "          [ 0.6221,  0.5707,  0.5364,  ..., -1.3473, -1.4158, -1.4500],\n",
            "          [ 0.7077,  0.6563,  0.6221,  ..., -1.3302, -1.3987, -1.4329],\n",
            "          [ 0.7591,  0.7077,  0.6734,  ..., -1.3130, -1.3815, -1.4158]],\n",
            "\n",
            "         [[-1.7031, -1.6506, -1.5805,  ...,  1.6057,  1.6057,  1.6057],\n",
            "          [-1.6506, -1.5980, -1.5280,  ...,  1.6057,  1.6057,  1.6057],\n",
            "          [-1.5805, -1.5280, -1.4405,  ...,  1.6057,  1.6057,  1.6057],\n",
            "          ...,\n",
            "          [ 0.0651,  0.0126, -0.0224,  ..., -1.4230, -1.5105, -1.5805],\n",
            "          [ 0.1527,  0.1001,  0.0651,  ..., -1.4055, -1.4930, -1.5630],\n",
            "          [ 0.2052,  0.1527,  0.1176,  ..., -1.3880, -1.4755, -1.5455]],\n",
            "\n",
            "         [[-1.7173, -1.6650, -1.6302,  ...,  1.2805,  1.2805,  1.2805],\n",
            "          [-1.6650, -1.6127, -1.5604,  ...,  1.2805,  1.2805,  1.2805],\n",
            "          [-1.5953, -1.5430, -1.4733,  ...,  1.2805,  1.2805,  1.2805],\n",
            "          ...,\n",
            "          [-0.3230, -0.3753, -0.4101,  ..., -1.3513, -1.4384, -1.5081],\n",
            "          [-0.2358, -0.2881, -0.3230,  ..., -1.3339, -1.4210, -1.4907],\n",
            "          [-0.1835, -0.2358, -0.2707,  ..., -1.3164, -1.4036, -1.4733]]]]) tensor([1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
            "        0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
            "        1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
            "        0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
            "        0, 1, 0, 1, 0, 1, 0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RS6-dGCxvZ2"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htLgyoMA5VN0",
        "outputId": "779c378f-91a1-48b7-93ce-d66974d822d0"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzfC_tkwzjWt",
        "outputId": "7c7cc724-56a5-4218-d46d-6f4eb15eb4a5"
      },
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.9.0', 'shufflenet_v2_x1_0', pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "dataloaders = {'train': train_dataloader, 'val': val_dataloader}\n",
        "dataset_sizes = {'train': len(train_files), 'val': len(val_files)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYGjItzt5ZLq",
        "outputId": "f6490d07-0b1a-4bca-cab4-e5a897098bae"
      },
      "source": [
        "# warm up\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "# optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.6553 Acc: 0.6552\n",
            "val Loss: 0.6207 Acc: 0.7236\n",
            "\n",
            "Training complete in 1m 18s\n",
            "Best val Acc: 0.723566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRfQ4xet9Tyy",
        "outputId": "4738c7d3-715f-4ac3-a56f-baa218dfc519"
      },
      "source": [
        "# fine-tuning\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.3227 Acc: 0.8631\n",
            "val Loss: 0.2212 Acc: 0.9075\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.1728 Acc: 0.9299\n",
            "val Loss: 0.2137 Acc: 0.9106\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.1050 Acc: 0.9600\n",
            "val Loss: 0.2252 Acc: 0.9161\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.0622 Acc: 0.9767\n",
            "val Loss: 0.3047 Acc: 0.9052\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.0409 Acc: 0.9854\n",
            "val Loss: 0.2827 Acc: 0.9163\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.0312 Acc: 0.9881\n",
            "val Loss: 0.3372 Acc: 0.9106\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.0216 Acc: 0.9917\n",
            "val Loss: 0.3630 Acc: 0.9116\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.0119 Acc: 0.9960\n",
            "val Loss: 0.3628 Acc: 0.9144\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.0073 Acc: 0.9976\n",
            "val Loss: 0.3567 Acc: 0.9145\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.0068 Acc: 0.9976\n",
            "val Loss: 0.3837 Acc: 0.9145\n",
            "\n",
            "Training complete in 15m 32s\n",
            "Best val Acc: 0.916339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs7BL-UVVREy"
      },
      "source": [
        "## save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtmxTqm5L6Hg"
      },
      "source": [
        "os.mkdir(\"./gender_shufflenetv2\")\n",
        "model_path = \"./gender_shufflenetv2/model.pt\"\n",
        "torch.save(model.state_dict(), model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmSM2FL2VV-s"
      },
      "source": [
        "## load and inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxcGydpcNKve"
      },
      "source": [
        "def eval_model(model, criterion):\n",
        "    since = time.time()\n",
        "\n",
        "    for epoch in range(1):\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Val complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgUwic2QMV12",
        "outputId": "4b0bb9ad-f23c-4b71-f87f-7e08bd62caac"
      },
      "source": [
        "new_model = torch.hub.load('pytorch/vision:v0.9.0', 'shufflenet_v2_x1_0', pretrained=True)\n",
        "\n",
        "num_ftrs = new_model.fc.in_features\n",
        "new_model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "new_model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "new_model = new_model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "eval_model(new_model, criterion)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.2827 Acc: 0.9163\n",
            "\n",
            "Val complete in 0m 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3-kq3YJY6u-"
      },
      "source": [
        "# Age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-EKrMy1ZGUf"
      },
      "source": [
        "class AgeDataset(Dataset):\n",
        "  def __init__(self, img_files, img_dir):\n",
        "    self.img_dir = img_dir\n",
        "    self.img_files = img_files\n",
        "    self.image_transforms = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_files)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_name = self.img_files[index]\n",
        "    age = float(img_name.split(\"_\")[0]) / 116\n",
        "    image = Image.open(os.path.join(self.img_dir, img_name))\n",
        "\n",
        "    image = self.image_transforms(image)\n",
        "\n",
        "    return image, age"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhB3UV6QZGUk",
        "outputId": "880cc22b-37f0-4bb1-be07-a2d9605664dc"
      },
      "source": [
        "img_dir = \"data/UTKFace/\"\n",
        "train_val_ratio = 0.3\n",
        "\n",
        "img_filenames = os.listdir(img_dir)\n",
        "random.shuffle(img_filenames)\n",
        "split = int(train_val_ratio * len(img_filenames))\n",
        "\n",
        "train_files = img_filenames[split:]\n",
        "val_files = img_filenames[:split]\n",
        "print(len(train_files), len(val_files))\n",
        "\n",
        "train_set = AgeDataset(train_files, img_dir)\n",
        "val_set = AgeDataset(val_files, img_dir)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "val_dataloader = DataLoader(val_set, batch_size=128, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16596 7112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5JAi7HAZGUp",
        "outputId": "6eaee2c5-0ac2-412b-ce12-7cf97d9d899a"
      },
      "source": [
        "for img, label in train_dataloader:\n",
        "  print(img, label)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[-1.0733, -1.2788, -1.5357,  ..., -1.8953, -1.8782, -1.8610],\n",
            "          [-1.1075, -1.3130, -1.5528,  ..., -1.8782, -1.8782, -1.8610],\n",
            "          [-1.1418, -1.3473, -1.5528,  ..., -1.8610, -1.8610, -1.8439],\n",
            "          ...,\n",
            "          [-0.6623, -0.6452, -0.6109,  ..., -1.8268, -1.8439, -1.8610],\n",
            "          [-0.6623, -0.6281, -0.5767,  ..., -1.8268, -1.8439, -1.8782],\n",
            "          [-0.6452, -0.5938, -0.5424,  ..., -1.8439, -1.8610, -1.8953]],\n",
            "\n",
            "         [[-1.2129, -1.4230, -1.6856,  ..., -1.9132, -1.8957, -1.8782],\n",
            "          [-1.2479, -1.4580, -1.7031,  ..., -1.8957, -1.8957, -1.8782],\n",
            "          [-1.2829, -1.4930, -1.7031,  ..., -1.8782, -1.8782, -1.8606],\n",
            "          ...,\n",
            "          [-0.9678, -0.9503, -0.9153,  ..., -1.8256, -1.8431, -1.8782],\n",
            "          [-0.9678, -0.9328, -0.8803,  ..., -1.8256, -1.8431, -1.8957],\n",
            "          [-0.9503, -0.8978, -0.8452,  ..., -1.8256, -1.8431, -1.8782]],\n",
            "\n",
            "         [[-1.1770, -1.3513, -1.6127,  ..., -1.6824, -1.6650, -1.6476],\n",
            "          [-1.2119, -1.3861, -1.6302,  ..., -1.6650, -1.6650, -1.6476],\n",
            "          [-1.2467, -1.4210, -1.6302,  ..., -1.6476, -1.6476, -1.6302],\n",
            "          ...,\n",
            "          [-0.9156, -0.8981, -0.8633,  ..., -1.6476, -1.6650, -1.6476],\n",
            "          [-0.9156, -0.8807, -0.8284,  ..., -1.6476, -1.6650, -1.6650],\n",
            "          [-0.8981, -0.8458, -0.7936,  ..., -1.6476, -1.6650, -1.6650]]],\n",
            "\n",
            "\n",
            "        [[[-1.5185, -1.4500, -1.3815,  ..., -1.5528, -1.6042, -1.5357],\n",
            "          [-1.5014, -1.3987, -1.3302,  ..., -1.7069, -1.7240, -1.6042],\n",
            "          [-1.4843, -1.3473, -1.2445,  ..., -1.7754, -1.7069, -1.5528],\n",
            "          ...,\n",
            "          [ 2.2147,  1.8037,  1.1358,  ...,  1.1187,  1.1187,  1.1015],\n",
            "          [ 2.0777,  1.4783,  0.7077,  ...,  1.1015,  1.0844,  1.0673],\n",
            "          [ 1.8550,  1.1529,  0.3481,  ...,  1.0673,  1.0502,  1.0502]],\n",
            "\n",
            "         [[-1.7381, -1.6681, -1.5980,  ..., -1.7906, -1.8431, -1.7731],\n",
            "          [-1.7031, -1.6155, -1.5280,  ..., -1.9482, -1.9657, -1.8431],\n",
            "          [-1.6856, -1.5455, -1.4405,  ..., -2.0007, -1.9482, -1.7906],\n",
            "          ...,\n",
            "          [ 1.8333,  1.3081,  0.4153,  ..., -1.4755, -1.4755, -1.4930],\n",
            "          [ 1.5532,  0.8179, -0.1800,  ..., -1.4930, -1.5105, -1.5280],\n",
            "          [ 1.1681,  0.3627, -0.6702,  ..., -1.5280, -1.5455, -1.5455]],\n",
            "\n",
            "         [[-1.6824, -1.6127, -1.5430,  ..., -1.6824, -1.7347, -1.6650],\n",
            "          [-1.6476, -1.5604, -1.4733,  ..., -1.7870, -1.7870, -1.7347],\n",
            "          [-1.6302, -1.4907, -1.3687,  ..., -1.8044, -1.7870, -1.6824],\n",
            "          ...,\n",
            "          [ 2.3786,  1.8557,  1.0017,  ..., -0.4624, -0.4624, -0.4798],\n",
            "          [ 2.0997,  1.4025,  0.4614,  ..., -0.4798, -0.4973, -0.5147],\n",
            "          [ 1.7685,  0.9842, -0.0092,  ..., -0.5147, -0.5321, -0.5321]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2489,  2.2489,  2.2489,  ...,  0.9817,  1.0502,  1.1015],\n",
            "          [ 2.2489,  2.2489,  2.2489,  ...,  0.9303,  0.9988,  1.0502],\n",
            "          [ 2.2489,  2.2489,  2.2489,  ...,  0.8789,  0.9303,  0.9817],\n",
            "          ...,\n",
            "          [-0.7137, -0.6623, -0.6109,  ..., -1.9467, -1.9467, -1.9467],\n",
            "          [-0.6965, -0.6623, -0.6109,  ..., -1.9638, -1.9638, -1.9638],\n",
            "          [-0.6965, -0.6623, -0.5938,  ..., -1.9638, -1.9809, -1.9809]],\n",
            "\n",
            "         [[ 2.3585,  2.3585,  2.3410,  ...,  0.5553,  0.6604,  0.7304],\n",
            "          [ 2.3585,  2.3585,  2.3410,  ...,  0.5028,  0.6078,  0.6779],\n",
            "          [ 2.3585,  2.3585,  2.3410,  ...,  0.4503,  0.5378,  0.6078],\n",
            "          ...,\n",
            "          [-0.9153, -0.8627, -0.8102,  ..., -1.8782, -1.8957, -1.8957],\n",
            "          [-0.8978, -0.8627, -0.8102,  ..., -1.8957, -1.9132, -1.9132],\n",
            "          [-0.8978, -0.8627, -0.7927,  ..., -1.9132, -1.9307, -1.9307]],\n",
            "\n",
            "         [[ 2.5180,  2.5180,  2.5006,  ...,  0.7576,  0.8971,  0.9842],\n",
            "          [ 2.5180,  2.5180,  2.5006,  ...,  0.7054,  0.8448,  0.9319],\n",
            "          [ 2.5180,  2.5180,  2.5006,  ...,  0.6531,  0.7751,  0.8448],\n",
            "          ...,\n",
            "          [-0.9330, -0.8807, -0.8284,  ..., -1.6650, -1.6476, -1.6476],\n",
            "          [-0.9156, -0.8807, -0.8284,  ..., -1.6824, -1.6650, -1.6650],\n",
            "          [-0.9156, -0.8807, -0.8110,  ..., -1.6999, -1.6824, -1.6824]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.8610, -1.8268, -1.8097,  ..., -1.0219, -1.0562, -1.0904],\n",
            "          [-1.8268, -1.8097, -1.7925,  ..., -1.0048, -1.0219, -1.0733],\n",
            "          [-1.8097, -1.7925, -1.7925,  ..., -1.0048, -1.0048, -1.0562],\n",
            "          ...,\n",
            "          [-0.8335, -1.1589, -1.3473,  ..., -0.9534, -0.9534, -0.9363],\n",
            "          [ 0.3994, -0.0972, -0.4568,  ..., -0.9363, -0.9363, -0.9363],\n",
            "          [ 1.9235,  1.3755,  0.8789,  ..., -0.9192, -0.9363, -0.9534]],\n",
            "\n",
            "         [[-1.7381, -1.7031, -1.6856,  ...,  0.9405,  0.9405,  0.9055],\n",
            "          [-1.7031, -1.6856, -1.6681,  ...,  0.9405,  0.9405,  0.9230],\n",
            "          [-1.6856, -1.6681, -1.6681,  ...,  0.9405,  0.9580,  0.9405],\n",
            "          ...,\n",
            "          [-1.0553, -1.4055, -1.6331,  ...,  0.9930,  0.9930,  1.0105],\n",
            "          [ 0.2402, -0.2850, -0.6877,  ...,  1.0105,  1.0105,  1.0105],\n",
            "          [ 1.8508,  1.2556,  0.6779,  ...,  1.0280,  1.0105,  0.9930]],\n",
            "\n",
            "         [[-1.5953, -1.5604, -1.5430,  ...,  2.2740,  2.2391,  2.2043],\n",
            "          [-1.5604, -1.5430, -1.5256,  ...,  2.2914,  2.2740,  2.2217],\n",
            "          [-1.5430, -1.5256, -1.5256,  ...,  2.2914,  2.2914,  2.2391],\n",
            "          ...,\n",
            "          [-0.8284, -1.1770, -1.4384,  ...,  2.3611,  2.3611,  2.3786],\n",
            "          [ 0.3742, -0.1661, -0.6018,  ...,  2.3786,  2.3786,  2.3786],\n",
            "          [ 1.8731,  1.2805,  0.7228,  ...,  2.3960,  2.3786,  2.3611]]],\n",
            "\n",
            "\n",
            "        [[[-0.3883, -0.5767, -0.6794,  ..., -1.3130, -1.2959, -1.2959],\n",
            "          [-0.4568, -0.6281, -0.7308,  ..., -1.3302, -1.3130, -1.2959],\n",
            "          [-0.6281, -0.7479, -0.8335,  ..., -1.3302, -1.3130, -1.2959],\n",
            "          ...,\n",
            "          [-0.6794, -0.5082, -0.3027,  ...,  1.4269,  1.5297,  1.6324],\n",
            "          [-0.6452, -0.4911, -0.2856,  ...,  1.4612,  1.5468,  1.6324],\n",
            "          [-0.6281, -0.4568, -0.2513,  ...,  1.4954,  1.5639,  1.6324]],\n",
            "\n",
            "         [[-0.5651, -0.7577, -0.8627,  ..., -1.4580, -1.4405, -1.4405],\n",
            "          [-0.6352, -0.8102, -0.9153,  ..., -1.4755, -1.4580, -1.4405],\n",
            "          [-0.7752, -0.8978, -0.9853,  ..., -1.4755, -1.4580, -1.4405],\n",
            "          ...,\n",
            "          [-0.6527, -0.4776, -0.3025,  ...,  1.3256,  1.4657,  1.5707],\n",
            "          [-0.6176, -0.4601, -0.2850,  ...,  1.3431,  1.4832,  1.5707],\n",
            "          [-0.6001, -0.4251, -0.2675,  ...,  1.3957,  1.5007,  1.5707]],\n",
            "\n",
            "         [[-0.4798, -0.6715, -0.7761,  ..., -1.2467, -1.2293, -1.2293],\n",
            "          [-0.5495, -0.7238, -0.8284,  ..., -1.2641, -1.2467, -1.2293],\n",
            "          [-0.6890, -0.7936, -0.8981,  ..., -1.2641, -1.2467, -1.2293],\n",
            "          ...,\n",
            "          [-0.4798, -0.3230, -0.1312,  ...,  1.2631,  1.3851,  1.5071],\n",
            "          [-0.4450, -0.3055, -0.1138,  ...,  1.2805,  1.4025,  1.5071],\n",
            "          [-0.4275, -0.2707, -0.0964,  ...,  1.3328,  1.4200,  1.5071]]],\n",
            "\n",
            "\n",
            "        [[[-1.6555, -1.6555, -1.6555,  ...,  1.4612,  1.4612,  1.4612],\n",
            "          [-1.6727, -1.6727, -1.6555,  ...,  1.4612,  1.4612,  1.4612],\n",
            "          [-1.6727, -1.6727, -1.6555,  ...,  1.4783,  1.4783,  1.4783],\n",
            "          ...,\n",
            "          [-1.1932, -1.1075, -0.9705,  ..., -0.4911, -0.4397, -0.4054],\n",
            "          [-1.2103, -1.1247, -0.9877,  ..., -0.4739, -0.4397, -0.4054],\n",
            "          [-1.2274, -1.1418, -1.0048,  ..., -0.4739, -0.4397, -0.4054]],\n",
            "\n",
            "         [[-1.8957, -1.8957, -1.8957,  ...,  1.5007,  1.5007,  1.5007],\n",
            "          [-1.9132, -1.9132, -1.8957,  ...,  1.5007,  1.5007,  1.5007],\n",
            "          [-1.9132, -1.9132, -1.8957,  ...,  1.5182,  1.5182,  1.5182],\n",
            "          ...,\n",
            "          [-1.7206, -1.6331, -1.4930,  ..., -0.8627, -0.8102, -0.7752],\n",
            "          [-1.7381, -1.6506, -1.5105,  ..., -0.8452, -0.8102, -0.7752],\n",
            "          [-1.7556, -1.6681, -1.5280,  ..., -0.8452, -0.8102, -0.7752]],\n",
            "\n",
            "         [[-1.7870, -1.7870, -1.7870,  ...,  1.4025,  1.4025,  1.4025],\n",
            "          [-1.8044, -1.8044, -1.7870,  ...,  1.4025,  1.4025,  1.4025],\n",
            "          [-1.8044, -1.8044, -1.7870,  ...,  1.4200,  1.4200,  1.4200],\n",
            "          ...,\n",
            "          [-1.7696, -1.6824, -1.5430,  ..., -1.0201, -0.9678, -0.9330],\n",
            "          [-1.7870, -1.6999, -1.5604,  ..., -1.0027, -0.9678, -0.9330],\n",
            "          [-1.8044, -1.7173, -1.5779,  ..., -1.0027, -0.9678, -0.9330]]]]) tensor([0.2069, 0.5431, 0.3362, 0.0172, 0.0172, 0.2069, 0.1983, 0.0086, 0.2241,\n",
            "        0.4914, 0.5431, 0.2586, 0.3103, 0.6897, 0.3534, 0.1552, 0.3276, 0.2069,\n",
            "        0.3276, 0.0086, 0.1983, 0.3017, 0.2241, 0.0690, 0.2500, 0.1379, 0.5948,\n",
            "        0.3448, 0.3190, 0.2155, 0.0086, 0.6466, 0.3448, 0.3621, 0.2586, 0.8276,\n",
            "        0.0259, 0.2241, 0.2241, 0.6897, 0.4569, 0.0690, 0.3276, 0.5431, 0.6293,\n",
            "        0.0086, 0.2069, 0.3017, 0.5000, 0.6293, 0.0776, 0.6897, 0.3966, 0.0690,\n",
            "        0.2414, 0.0172, 0.3276, 0.2586, 0.7759, 0.4569, 0.4310, 0.3448, 0.4569,\n",
            "        0.4310, 0.1897, 0.2328, 0.5603, 0.2414, 0.2500, 0.6810, 0.1552, 0.2414,\n",
            "        0.0086, 0.3017, 0.6466, 0.1810, 0.0431, 0.5776, 0.1552, 0.0086, 0.2155,\n",
            "        0.4655, 0.2069, 0.4397, 0.2759, 0.4741, 0.3103, 0.5086, 0.0172, 0.3448,\n",
            "        0.2328, 0.2414, 0.3276, 0.5690, 0.2500, 0.0776, 0.0862, 0.2155, 0.2069,\n",
            "        0.0776, 0.7328, 0.2586, 0.2414, 0.0086, 0.6034, 0.4224, 0.3448, 0.1293,\n",
            "        0.2241, 0.5431, 0.3707, 0.3534, 0.2500, 0.0862, 0.0431, 0.1379, 0.2241,\n",
            "        0.1034, 0.2759, 0.2069, 0.4828, 0.1897, 0.2500, 0.0172, 0.6897, 0.1466,\n",
            "        0.6897, 0.2328], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuWEajZMuBxy"
      },
      "source": [
        "# import torchvision\n",
        "\n",
        "# def imshow(inp, title=None):\n",
        "#     \"\"\"Imshow for Tensor.\"\"\"\n",
        "#     inp = inp.numpy().transpose((1, 2, 0))\n",
        "#     mean = np.array([0.485, 0.456, 0.406])\n",
        "#     std = np.array([0.229, 0.224, 0.225])\n",
        "#     inp = std * inp + mean\n",
        "#     inp = np.clip(inp, 0, 1)\n",
        "#     plt.imshow(inp)\n",
        "#     if title is not None:\n",
        "#         plt.title(title)\n",
        "#     plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# # Get a batch of training data\n",
        "# inputs, classes = next(iter(train_dataloader))\n",
        "\n",
        "# # Make a grid from batch\n",
        "# out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "# imshow(out, title=[x.item() for x in classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT8-OuXNZGUv"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_mae = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            # epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Mae: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_loss))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_loss < best_mae:\n",
        "                best_mae = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Mae: {:4f}'.format(best_mae))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1-R1YXhZGUw",
        "outputId": "a39daf39-a2b0-4e13-c691-1b5d15242aa2"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30oW5WL5ZGUy",
        "outputId": "072032fe-e365-4c0d-bde0-df634630f436"
      },
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.9.0', 'shufflenet_v2_x1_0', pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 1)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "dataloaders = {'train': train_dataloader, 'val': val_dataloader}\n",
        "dataset_sizes = {'train': len(train_files), 'val': len(val_files)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PhIGkdkZGUy",
        "outputId": "a32ab6a8-ea94-4c8b-d9a8-0b587b1ccbf7"
      },
      "source": [
        "# warm up\n",
        "\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "# optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/0\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([84])) that is different to the input size (torch.Size([84, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.1389 Mae: 0.1389\n",
            "val Loss: 0.1295 Mae: 0.1295\n",
            "\n",
            "Training complete in 1m 27s\n",
            "Best val Mae: 0.129487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([72])) that is different to the input size (torch.Size([72, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqeAErfdZGU0",
        "outputId": "64b01fb8-75ad-48df-f843-64810dfb9653"
      },
      "source": [
        "# fine-tuning\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.0003, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([84])) that is different to the input size (torch.Size([84, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.1305 Mae: 0.1305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([72])) that is different to the input size (torch.Size([72, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.1283 Mae: 0.1283\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.1301 Mae: 0.1301\n",
            "val Loss: 0.1274 Mae: 0.1274\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.1302 Mae: 0.1302\n",
            "val Loss: 0.1275 Mae: 0.1275\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.1301 Mae: 0.1301\n",
            "val Loss: 0.1274 Mae: 0.1274\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.1301 Mae: 0.1301\n",
            "val Loss: 0.1274 Mae: 0.1274\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.1301 Mae: 0.1301\n",
            "val Loss: 0.1274 Mae: 0.1274\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.1301 Mae: 0.1301\n",
            "val Loss: 0.1274 Mae: 0.1274\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.1299 Mae: 0.1299\n",
            "val Loss: 0.1274 Mae: 0.1274\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.1299 Mae: 0.1299\n",
            "val Loss: 0.1274 Mae: 0.1274\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.1299 Mae: 0.1299\n",
            "val Loss: 0.1274 Mae: 0.1274\n",
            "\n",
            "Training complete in 17m 5s\n",
            "Best val Mae: 0.128278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdWogqqWZGU2"
      },
      "source": [
        "## save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca-1WCXCZGU3"
      },
      "source": [
        "os.mkdir(\"./age_shufflenetv2\")\n",
        "model_path = \"./age_shufflenetv2/model.pt\"\n",
        "torch.save(model.state_dict(), model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH85_UBfZGU4"
      },
      "source": [
        "## load and inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FZa92cTZGU4"
      },
      "source": [
        "def eval_model(model, criterion):\n",
        "    since = time.time()\n",
        "\n",
        "    # best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    # best_mae = 0.0\n",
        "\n",
        "    for epoch in range(1):\n",
        "        # print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        # print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Mae: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_loss))\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Val complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPxdNlyvZGU5",
        "outputId": "510fd9be-7d37-4b51-b2d8-29e14c1714a6"
      },
      "source": [
        "new_model = torch.hub.load('pytorch/vision:v0.9.0', 'shufflenet_v2_x1_0', pretrained=True)\n",
        "\n",
        "num_ftrs = new_model.fc.in_features\n",
        "new_model.fc = nn.Linear(num_ftrs, 1)\n",
        "\n",
        "new_model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "new_model = new_model.to(device)\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "eval_model(new_model, criterion)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.1283 Mae: 0.1283\n",
            "\n",
            "Val complete in 0m 26s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([72])) that is different to the input size (torch.Size([72, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_x0iMiceyjE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYGPpCD2juQD"
      },
      "source": [
        "# download the model file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPYmFEM_jyb5",
        "outputId": "9ff5560b-31ad-4618-bd40-7b205270cda8"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTGnQEzUkSPF",
        "outputId": "03ac84d9-dca0-431f-d865-bd3da4177546"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age_shufflenetv2  data\tdrive  gender_shufflenetv2  sample_data  UTKFace.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcwR1E-HkUXs"
      },
      "source": [
        "!cp -R \"./age_shufflenetv2\" \"/content/drive/MyDrive/Colab Notebooks/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDxCHLwzkf5Y"
      },
      "source": [
        "!cp -R \"./gender_shufflenetv2\" \"/content/drive/MyDrive/Colab Notebooks/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT1c-wyOkl7u",
        "outputId": "139992fb-c632-42d8-b08f-0bfa2e286347"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age_shufflenetv2  data\tdrive  gender_shufflenetv2  sample_data  UTKFace.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2URXVAgQpg-v",
        "outputId": "ff30acfa-c910-410a-f5ca-53d8717e808d"
      },
      "source": [
        "!gdown --id \"1nXHFCYHm9bQ3shB_4INU5c_VuMPckPZh\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Permission denied: https://drive.google.com/uc?id=1nXHFCYHm9bQ3shB_4INU5c_VuMPckPZh\n",
            "Maybe you need to change permission over 'Anyone with the link'?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U99y-oAfp-Oh",
        "outputId": "06853a80-c92a-48a6-94a0-07830559fd3a"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1nXHFCYHm9bQ3shB_4INU5c_VuMPckPZh/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdOvd7xbrTQd",
        "outputId": "5ade9702-b667-4477-e74c-7131b011b035"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1nXHFCYHm9bQ3shB_4INU5c_VuMPckPZh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQHy33yNrXzn",
        "outputId": "f3f459a9-117a-400a-d717-cf6ee84c76b6"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml-SnvCNraWt",
        "outputId": "71ea47df-4f8b-4699-d203-5d07ce912c5d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age_shufflenetv2  data\tdrive  gender_shufflenetv2  sample_data  UTKFace.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_UNvg9asGhM"
      },
      "source": [
        "TEST_DIR = \"/content/drive/.shortcut-targets-by-id/1nXHFCYHm9bQ3shB_4INU5c_VuMPckPZh/data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4TCzE_5rjy_"
      },
      "source": [
        "## test age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFKnlQQkrusV"
      },
      "source": [
        "class AgeDataset(Dataset):\n",
        "  def __init__(self, img_files, img_dir):\n",
        "    self.img_dir = img_dir\n",
        "    self.img_files = img_files\n",
        "    self.image_transforms = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_files)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_name = self.img_files[index]\n",
        "    age = float(img_name.split(\"_\")[0]) / 116\n",
        "    image = Image.open(os.path.join(self.img_dir, img_name))\n",
        "\n",
        "    image = self.image_transforms(image)\n",
        "\n",
        "    return image, age"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXhQvHxKrusc",
        "outputId": "613dda1a-c8b6-47ab-f6ef-7235b2428fe0"
      },
      "source": [
        "img_dir = TEST_DIR\n",
        "# train_val_ratio = 0.3\n",
        "\n",
        "img_filenames = os.listdir(img_dir)\n",
        "# random.shuffle(img_filenames)\n",
        "# split = int(train_val_ratio * len(img_filenames))\n",
        "\n",
        "val_files = img_filenames\n",
        "print(len(val_files))\n",
        "\n",
        "val_set = AgeDataset(val_files, img_dir)\n",
        "\n",
        "val_dataloader = DataLoader(val_set, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jF0MqWQsjUf",
        "outputId": "84453eb0-28fd-44a4-d6f7-8577d633a237"
      },
      "source": [
        "dataloaders = {'val': val_dataloader}\n",
        "dataset_sizes = {'val': len(val_files)}\n",
        "\n",
        "def eval_model(model, criterion):\n",
        "    since = time.time()\n",
        "\n",
        "    # best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    # best_mae = 0.0\n",
        "\n",
        "    for epoch in range(1):\n",
        "        # print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        # print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Mae: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_loss))\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Val complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "\n",
        "new_model = torch.hub.load('pytorch/vision:v0.9.0', 'shufflenet_v2_x1_0', pretrained=True)\n",
        "\n",
        "num_ftrs = new_model.fc.in_features\n",
        "new_model.fc = nn.Linear(num_ftrs, 1)\n",
        "\n",
        "model_path = \"./age_shufflenetv2/model.pt\"\n",
        "new_model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "new_model = new_model.to(device)\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "eval_model(new_model, criterion)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.1101 Mae: 0.1101\n",
            "\n",
            "Val complete in 0m 28s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([61])) that is different to the input size (torch.Size([61, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho7W9kZCtVuo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9V1Ep7QtZNk"
      },
      "source": [
        "## test gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfr1JqRcta8n"
      },
      "source": [
        "class AgeDataset(Dataset):\n",
        "  def __init__(self, img_files, img_dir):\n",
        "    self.img_dir = img_dir\n",
        "    self.img_files = img_files\n",
        "    self.image_transforms = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_files)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_name = self.img_files[index]\n",
        "    gender = int(img_name.split(\"_\")[1])\n",
        "    image = Image.open(os.path.join(self.img_dir, img_name))\n",
        "\n",
        "    image = self.image_transforms(image)\n",
        "    gender = torch.tensor(gender, dtype=torch.long)\n",
        "\n",
        "    return image, gender"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KR6sXv3tmUP",
        "outputId": "c984e084-0eca-4061-f773-738a532dd80c"
      },
      "source": [
        "img_dir = TEST_DIR\n",
        "img_filenames = os.listdir(img_dir)\n",
        "\n",
        "val_files = img_filenames\n",
        "print(len(val_files))\n",
        "\n",
        "val_set = AgeDataset(val_files, img_dir)\n",
        "\n",
        "val_dataloader = DataLoader(val_set, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKK8TiBVtyEQ",
        "outputId": "3870ba78-0655-4ae4-ed25-3f2eafdd10e4"
      },
      "source": [
        "dataloaders = {'val': val_dataloader}\n",
        "dataset_sizes = {'val': len(val_files)}\n",
        "\n",
        "def eval_model(model, criterion):\n",
        "    since = time.time()\n",
        "\n",
        "    for epoch in range(1):\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Val complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    \n",
        "new_model = torch.hub.load('pytorch/vision:v0.9.0', 'shufflenet_v2_x1_0', pretrained=True)\n",
        "\n",
        "num_ftrs = new_model.fc.in_features\n",
        "new_model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_path = \"./gender_shufflenetv2/model.pt\"\n",
        "new_model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "new_model = new_model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "eval_model(new_model, criterion)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.1811 Acc: 0.9344\n",
            "\n",
            "Val complete in 0m 0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHLzYjgkuMAp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}